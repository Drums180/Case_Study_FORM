}
# Combinar los archivos
clientes_combinados <- bind_rows(clientes_trad, omd_censo)
# Eliminar duplicados, manteniendo el último (de omd_censo)
clientes_unicos <- clientes_combinados %>%
arrange(desc(customercode)) %>%
distinct(customercode, .keep_all = TRUE)
# Aplica limpiar nombres a las tablas en all_dfs
all_dfs <- lapply(all_dfs, function(df) {
names(df) <- limpiar_nombres(names(df))
return(df)
})
# Tomar el dataframe 'mds' de all_dfs:
mds <- all_dfs[["Clientes"]]  # Ajusta el nombre según corresponda si es diferente
# Elimina registros duplicados en mds basados en codigo_cliente
mds <- mds %>%
limpiar_nombres() %>%
group_by(codigo_cliente) %>%
filter(row_number() == 1) %>%
ungroup()
# Creación de la columna 'tamaño' en 'mds'
mds <- mds %>%
mutate(
tamaño = ifelse(canal_rgm == "Comer y Beber",
tamaño_de_cliente,
tamaño_de_cliente_industria)
) %>%
mutate(tamaño = tolower(tamaño)) %>%
mutate(
tamaño = case_when(
tamaño == "micro" ~ "MI",
tamaño == "pequeño" ~ "CH",
tamaño == "mediano" ~ "M",
tamaño == "grande" ~ "G",
tamaño == "extra grande" ~ "XG",
TRUE ~ tamaño
)
)
# Hacer el left_join con clientes
master_clientes <- clientes_unicos %>%
left_join(mds[, c("codigo_cliente", "tamaño", "sub_canal_isscom", "modelo_de_servicio_ruta", "ruta_preventa_oficial", "zona...13", "territorio...14")],
by = c("customercode" = "codigo_cliente"))
# Verificar el resultado
head(master_clientes)
# Cargar la hoja "data" del archivo "parametros"
parametros_data <- read_excel("parametros.xlsx", sheet = "data")
# Verificar la carga de datos
head(parametros_data)
df_survey <- df_survey %>%
mutate(duration = `Duration(Sec)` / 60) %>%
mutate(estatus = if_else(Status == "Complete", 1, 0))
# Verificar los cambios
head(df_survey)
# Función del haversine para calcular distancia entre dos puntos de latitud y longitud
haversine <- function(lon1, lat1, lon2, lat2) {
R <- 6371000  # Radio de la Tierra en metros
phi1 <- lat1 * (pi / 180)
phi2 <- lat2 * (pi / 180)
delta_phi <- (lat2 - lat1) * (pi / 180)
delta_lambda <- (lon2 - lon1) * (pi / 180)
a <- sin(delta_phi / 2)^2 + cos(phi1) * cos(phi2) * sin(delta_lambda / 2)^2
c <- 2 * atan2(sqrt(a), sqrt(1 - a))
d <- R * c  # Distancia en metros
return(d)
}
# Convertir las columnas relevantes a character
df_session$OutletCode <- as.character(df_session$OutletCode)
master_clientes$customercode <- as.character(master_clientes$customercode)
# Realizar el join y calcular la distancia usando la función haversine
df_session <- df_session %>%
left_join(select(master_clientes, customercode, latitude, longitude),
by = c("OutletCode" = "customercode")) %>%
mutate(
distance = mapply(haversine, longitude, latitude, SessionEndLongitude, SessionEndLatitude)
)
# Calculamos los cuartiles y el rango intercuartil de la distancia
Q1 <- quantile(df_session$distance, 0.25, na.rm = TRUE)
Q3 <- quantile(df_session$distance, 0.75, na.rm = TRUE)
IQR <- Q3 - Q1
# Reemplazar valores atípicos por 0
df_session$distance[df_session$distance < (Q1 - 1.5 * IQR) |
df_session$distance > (Q3 + 1.5 * IQR)] <- 0
# Identificar valores atípicos
outliers <- df_session$distance[df_session$distance < (Q1 - 1.5 * IQR) |
df_session$distance > (Q3 + 1.5 * IQR)]
# Imprimir valores atípicos
print(outliers)
# Verificar los cambios
head(df_session)
frentes_df <- df_actual %>%
group_by(SessionUID) %>%
summarise(
# Cálculo de num_frentes
num_frentes = sum(ProductName != "Foreign" & IsEmpty == FALSE),
# Cálculo de frentes_com
frentes_com = sum(ProductName != "Foreign" & IsForeign == TRUE),
# Cálculo de frentes_total
frentes_total = sum(ProductName != "Foreign" & IsEmpty == FALSE)
) %>%
mutate(
# Cálculo de frentes_arca
frentes_arca = frentes_total - frentes_com,
# Cálculo de sovi
sovi = ifelse(frentes_total == 0, 0, frentes_arca / frentes_total)
)
# Verificar el nuevo dataframe
head(frentes_df)
result_enfriadores <- df_scenes %>%
# Agrupar por SessionUID y SubSceneType y contar
group_by(SessionUID, SubSceneType) %>%
count() %>%
# Transforma valores de SubSceneType en columnas individuales
spread(key = SubSceneType, value = n, fill = 0) %>% # fill = 0 para llenar con 0s donde no haya conteos
ungroup()
# Funcion para sumar Enfriadores
# Genera las columnas si no existen
if (!"Enfriador AC" %in% names(result_enfriadores)) {
result_enfriadores$`Enfriador AC` <- 0
}
if (!"Enfriador AC CEDIDO" %in% names(result_enfriadores)) {
result_enfriadores$`Enfriador AC CEDIDO` <- 0
}
# Suma las columnas
result_enfriadores <- result_enfriadores %>%
mutate(enfriador_total = `Enfriador AC` + `Enfriador AC CEDIDO`)
# Verificar el resultado
head(result_enfriadores)
# Paso 1: Crear df con SceneUID, MaxDoorIndex, y SessionUID basado en df_actual
df_actual_maxdoorindex <- df_actual %>%
group_by(SceneUID) %>%
summarise(MaxDoorIndex = max(DoorIndex, na.rm = TRUE)) %>%
left_join(df_actual %>% select(SceneUID, SessionUID) %>% distinct(), by = "SceneUID")
# Paso 2: Hacer join con df_scenes para agregar SceneType
df_joined <- df_actual_maxdoorindex %>%
left_join(df_scenes %>% select(SceneUID, SceneType) %>% distinct(), by = "SceneUID")
# Paso 3: Calcular la cantidad de escenas de cada tipo y el total por SessionUID
# Calculando el total de escenas por SessionUID
df_total_scenes <- df_joined %>%
group_by(SessionUID) %>%
summarise(Total_Scenes = n(), .groups = "drop")
# Calculando escenas de tipo 'Ambiente'
df_ambiente <- df_joined %>%
filter(SceneType == "AMBIENTE") %>%
group_by(SessionUID) %>%
summarise(Ambiente_Scenes = n(), .groups = "drop")
# Calculando escenas de tipo 'Frio'
df_frio <- df_joined %>%
filter(SceneType == "FRIO") %>%
group_by(SessionUID) %>%
summarise(Frio_Scenes = n(), .groups = "drop")
# Uniendo los dataframes para tener el total y los tipos específicos en uno
df_summary <- df_total_scenes %>%
left_join(df_ambiente, by = "SessionUID") %>%
left_join(df_frio, by = "SessionUID") %>%
replace_na(list(Ambiente_Scenes = 0, Frio_Scenes = 0)) # Reemplazar NA con 0
# Mostrando el dataframe final
print(df_summary)
# Creación del vector de valores de flag
flag_values <- c(2, 4, 13, 14, 15, 16, 26, 27, 32, 36, 39, 31)
#-------------------------------------------------------------
# Función para dividir la cadena en pares y añadir comas
format_image_quality <- function(value) {
# Divide la cadena en pares de caracteres
split_values <- str_extract_all(value, ".{1,2}")[[1]]
# Une los valores con comas
paste(split_values, collapse = ",")
}
# Aplica la función a la columna ImageQuality
df_scenes$ImageQuality <- sapply(df_scenes$ImageQuality, format_image_quality)
# Ahora procede con la agrupación y concatenación
result_scenes <- df_scenes %>%
group_by(SessionUID) %>%
summarise(ImageQuality = paste(unique(ImageQuality), collapse = ",")) %>%
ungroup()
#--------------------------------------------------------------
# Función para detectar las flags en la columna ImageQuality
detect_flags <- function(quality_string) {
quality_values <- as.numeric(unlist(strsplit(quality_string, ",")))  # Divide la cadena y convierte a numéricos
detected <- quality_values[quality_values %in% flag_values]
if(length(detected) > 0) {
return(paste(detected, collapse = ","))
} else {
return(NA_character_)
}
}
# Función para comprobar si alguno de los valores de flag está en la columna ImageQuality
check_flags <- function(quality_string) {
quality_values <- as.numeric(unlist(strsplit(quality_string, ",")))  # Divide la cadena y convierte a numéricos
if(any(quality_values %in% flag_values)) {
return(-100)
} else {
return(100)
}
}
# Aplicar ambas funciones a la columna ImageQuality de result_scenes
result_scenes$flag_trigger <- sapply(result_scenes$ImageQuality, check_flags)
result_scenes$detected_flags <- sapply(result_scenes$ImageQuality, detect_flags)
# Verificar el resultado
head(result_scenes)
master_clientes <- master_clientes %>%
mutate(
cuota_diaria = case_when(
modelo_de_servicio_ruta == "PRE ESPECIALIZADA" ~ 3,
modelo_de_servicio_ruta == "PREVENTA 24" ~ 2,
modelo_de_servicio_ruta == "PREVENTA 48 FORANEO" ~ 1,
modelo_de_servicio_ruta == "PRE MDO TRADICIONA" ~ 2,
modelo_de_servicio_ruta == "PRE MICRO MERCADOS" ~ 3,
modelo_de_servicio_ruta == "PREVENTA 72 FOR" ~ 1,
modelo_de_servicio_ruta == "PREVENTA 48 METROPOLITANO" ~ 1,
modelo_de_servicio_ruta == "PRE COMERCIAL" ~ 2,
modelo_de_servicio_ruta == "PREVENTA NCBS" ~ 3,
TRUE ~ NA_real_
)
)
# Verificar el resultado
head(master_clientes)
master_calidad <- df_survey %>%
select(SessionUID = "Session Uid", SurveyType = "Survey Type", User, `Outlet Code`, duration, `Survey End Time`, estatus) %>%
# Unión con master_clientes
left_join(master_clientes %>%
mutate(customercode = as.character(customercode)) %>%
select(customercode, tamaño, salesorganizationcode, tradechannelcode, sub_canal_isscom, modelo_de_servicio_ruta, salesterritorycode, territorio...14),
by = c("Outlet Code" = "customercode")) %>%
# Incorporar columnas de df_session
left_join(df_session %>% select(SessionUId, distance),
by = c("SessionUID" = "SessionUId")) %>%
# Incorporar métricas de frentes_df
left_join(frentes_df %>% select(SessionUID, frentes_total, frentes_arca, sovi),
by = "SessionUID") %>%
# Incorporar columna flag_trigger de result_scenes
left_join(result_scenes %>% select(SessionUID, flag_trigger, detected_flags),
by = "SessionUID") %>%
# Incorporar columna enfriador_total de result_enfriadores
left_join(result_enfriadores %>% select(SessionUID, enfriador_total),
by = "SessionUID") %>%
# Incorporar columna scenes de df_summary
left_join(df_summary %>% select(SessionUID, Total_Scenes, Ambiente_Scenes, Frio_Scenes),
by = "SessionUID") %>%
# Seleccionar y reordenar columnas
select(
SessionUID, SurveyType, User, `Outlet Code`,
salesorganizationcode, tamaño, tradechannelcode, sub_canal_isscom,
duration, distance,
frentes_total, frentes_arca, sovi, flag_trigger, enfriador_total, Total_Scenes, Ambiente_Scenes, Frio_Scenes, detected_flags,
modelo_de_servicio_ruta, salesterritorycode, territorio...14, `Survey End Time`, estatus
)
# Verificar el nuevo dataframe
head(master_calidad)
# Función para limpiar directorio de archivos individuales, manteniendo solo el combinado
clean_directory <- function(path) {
combined_file_path <- file.path(path, "combined.csv")
# Listar todos los archivos excepto el archivo combinado
files_to_delete <- setdiff(list.files(path, full.names = TRUE), combined_file_path)
# Eliminar archivos
file.remove(files_to_delete)
}
# Limpiar directorios de archivos individuales
clean_directory("fuentes_datos/session/")
clean_directory("fuentes_datos/survey/")
# 1. Contar los SceneUID distintos para cada SessionUID
scene_count_df <- df_actual %>%
group_by(SessionUID) %>%
summarise(min_frentes = n_distinct(SceneUID) * 3)
# Unir temporalmente con master_calidad para aplicar las condiciones
master_calidad_temp <- left_join(master_calidad, scene_count_df, by = "SessionUID")
# Actualizar las flags de acuerdo con las condiciones
master_calidad <- master_calidad_temp %>%
mutate(
# Flag para 0 frentes totales
detected_flags = ifelse(frentes_total == 0,
ifelse(is.na(detected_flags), "66", paste(detected_flags, ",66", sep="")),
detected_flags),
flag_trigger = ifelse(frentes_total == 0, -100, flag_trigger),
# Flag para frentes insuficientes
detected_flags = ifelse(frentes_total < min_frentes,
ifelse(is.na(detected_flags), "61", paste(detected_flags, ",61", sep="")),
detected_flags),
flag_trigger = ifelse(frentes_total < min_frentes, -100, flag_trigger),
# Nueva flag para enfriador_total no nulo y frentes_total nulo
detected_flags = ifelse(!is.na(enfriador_total) & is.na(frentes_total),
ifelse(is.na(detected_flags), "-100", paste(detected_flags, ",-100", sep="")),
detected_flags),
flag_trigger = ifelse(!is.na(enfriador_total) & is.na(frentes_total), -100, flag_trigger)
) %>%
select(-min_frentes)  # Eliminamos la columna temporal min_frentes
head(master_calidad)
master_calidad <- master_calidad %>%
mutate(
`Survey End Time` = as.Date(substr(`Survey End Time`, 1, 10), format = "%d/%m/%Y")
)
# Corregir la columna 'detected_flags' para asegurar que haya comas entre cada dos caracteres
master_calidad$detected_flags <- str_replace_all(master_calidad$detected_flags, "(\\d{2})(?!$)", "\\1,")
# Verificar los primeros registros para asegurar que la corrección se aplicó correctamente
head(master_calidad)
# Paso 1: Unión con parametros_data
master_evaluado <- master_calidad %>%
left_join(parametros_data, by = c("tamaño", "tradechannelcode", "sub_canal_isscom"))
# Paso 2: Generar subconjuntos basados en combinaciones de tradechannelcode, tamaño y sub_canal_isscom "General"
comer_beber_MI <- parametros_data[parametros_data$tradechannelcode == "Comer y Beber" & parametros_data$tamaño == "MI" & parametros_data$sub_canal_isscom == "General", ]
comer_beber_CH <- parametros_data[parametros_data$tradechannelcode == "Comer y Beber" & parametros_data$tamaño == "CH" & parametros_data$sub_canal_isscom == "General", ]
comer_beber_M  <- parametros_data[parametros_data$tradechannelcode == "Comer y Beber" & parametros_data$tamaño == "M"  & parametros_data$sub_canal_isscom == "General", ]
comer_beber_G  <- parametros_data[parametros_data$tradechannelcode == "Comer y Beber" & parametros_data$tamaño == "G"  & parametros_data$sub_canal_isscom == "General", ]
comer_beber_XG <- parametros_data[parametros_data$tradechannelcode == "Comer y Beber" & parametros_data$tamaño == "XG" & parametros_data$sub_canal_isscom == "General", ]
tradicional_MI <- parametros_data[parametros_data$tradechannelcode == "Tradicional" & parametros_data$tamaño == "MI" & parametros_data$sub_canal_isscom == "General", ]
tradicional_CH <- parametros_data[parametros_data$tradechannelcode == "Tradicional" & parametros_data$tamaño == "CH" & parametros_data$sub_canal_isscom == "General", ]
tradicional_M  <- parametros_data[parametros_data$tradechannelcode == "Tradicional" & parametros_data$tamaño == "M"  & parametros_data$sub_canal_isscom == "General", ]
tradicional_G  <- parametros_data[parametros_data$tradechannelcode == "Tradicional" & parametros_data$tamaño == "G"  & parametros_data$sub_canal_isscom == "General", ]
tradicional_XG <- parametros_data[parametros_data$tradechannelcode == "Tradicional" & parametros_data$tamaño == "XG" & parametros_data$sub_canal_isscom == "General", ]
# Corrección del Paso 2 y 3: Usar bucle para iterar sobre columnas y reemplazar NAs
cols_to_modify <- c("lower_bound_frentes", "upper_bound_frentes",
"lower_bound_enfriadores","upper_bound_enfriadores",
"lower_bound_duration", "upper_bound_duration","lower_bound_ScenesFrio", "upper_bound_ScenesFrio",  "lower_bound_frentes_arca", "upper_bound_frentes_arca", "upper_bound_ScenesAmb", "lower_bound_NumScenes", "upper_bound_NumScenes")
for(col in cols_to_modify) {
# Comer y Beber
master_evaluado[[col]] <- ifelse(is.na(master_evaluado[[col]]) & master_evaluado$tradechannelcode == "Comer y Beber" & master_evaluado$tamaño == "MI", comer_beber_MI[[col]], master_evaluado[[col]])
master_evaluado[[col]] <- ifelse(is.na(master_evaluado[[col]]) & master_evaluado$tradechannelcode == "Comer y Beber" & master_evaluado$tamaño == "CH", comer_beber_CH[[col]], master_evaluado[[col]])
master_evaluado[[col]] <- ifelse(is.na(master_evaluado[[col]]) & master_evaluado$tradechannelcode == "Comer y Beber" & master_evaluado$tamaño == "M",  comer_beber_M[[col]],  master_evaluado[[col]])
master_evaluado[[col]] <- ifelse(is.na(master_evaluado[[col]]) & master_evaluado$tradechannelcode == "Comer y Beber" & master_evaluado$tamaño == "G",  comer_beber_G[[col]],  master_evaluado[[col]])
master_evaluado[[col]] <- ifelse(is.na(master_evaluado[[col]]) & master_evaluado$tradechannelcode == "Comer y Beber" & master_evaluado$tamaño == "XG", comer_beber_XG[[col]], master_evaluado[[col]])
# Tradicional
master_evaluado[[col]] <- ifelse(is.na(master_evaluado[[col]]) & master_evaluado$tradechannelcode == "Tradicional" & master_evaluado$tamaño == "MI", tradicional_MI[[col]], master_evaluado[[col]])
master_evaluado[[col]] <- ifelse(is.na(master_evaluado[[col]]) & master_evaluado$tradechannelcode == "Tradicional" & master_evaluado$tamaño == "CH", tradicional_CH[[col]], master_evaluado[[col]])
master_evaluado[[col]] <- ifelse(is.na(master_evaluado[[col]]) & master_evaluado$tradechannelcode == "Tradicional" & master_evaluado$tamaño == "M",  tradicional_M[[col]],  master_evaluado[[col]])
master_evaluado[[col]] <- ifelse(is.na(master_evaluado[[col]]) & master_evaluado$tradechannelcode == "Tradicional" & master_evaluado$tamaño == "G",  tradicional_G[[col]],  master_evaluado[[col]])
master_evaluado[[col]] <- ifelse(is.na(master_evaluado[[col]]) & master_evaluado$tradechannelcode == "Tradicional" & master_evaluado$tamaño == "XG", tradicional_XG[[col]], master_evaluado[[col]])
# Para los NA en tradechannelcode
master_evaluado[[col]] <- ifelse(is.na(master_evaluado[[col]]) & is.na(master_evaluado$tradechannelcode) & master_evaluado$tamaño == "M", tradicional_M[[col]], master_evaluado[[col]])
# Caso donde tamaño es NA pero tradechannelcode es "Comer y Beber"
master_evaluado[[col]] <- ifelse(is.na(master_evaluado[[col]]) & is.na(master_evaluado$tamaño) & master_evaluado$tradechannelcode == "Comer y Beber", comer_beber_M[[col]], master_evaluado[[col]])
# Caso donde tamaño es NA pero tradechannelcode es "Tradicional"
master_evaluado[[col]] <- ifelse(is.na(master_evaluado[[col]]) & is.na(master_evaluado$tamaño) & master_evaluado$tradechannelcode == "Tradicional", tradicional_M[[col]], master_evaluado[[col]])
}
# Paso 4
# Imputación final para reemplazar cualquier NA restante con los valores de 'tradicional_M'
for(col in cols_to_modify) {
master_evaluado[[col]] <- ifelse(is.na(master_evaluado[[col]]), tradicional_M[[col]], master_evaluado[[col]])
}
# Paso 5: Calificación
master_evaluado <- master_evaluado %>%
mutate(
# Calificación para frentes_total
score_frentes_total = case_when(
frentes_total >= lower_bound_frentes & frentes_total <= upper_bound_frentes ~ 100,
frentes_total >= (lower_bound_frentes - 0.1 * (upper_bound_frentes - lower_bound_frentes)) &
frentes_total <= (upper_bound_frentes + 0.1 * (upper_bound_frentes - lower_bound_frentes)) ~ 50,
TRUE ~ 0
),
# Calificación para frentes_total
score_frentes_arca = case_when(
frentes_arca >= lower_bound_frentes_arca & frentes_arca <= upper_bound_frentes_arca ~ 100,
frentes_arca >= (lower_bound_frentes_arca - 0.01 * (upper_bound_frentes_arca - lower_bound_frentes_arca)) &
frentes_arca <= (upper_bound_frentes_arca + 0.01 * (upper_bound_frentes_arca - lower_bound_frentes_arca)) ~ 50,
TRUE ~ 0
),
# Calificación para duration
score_duration = case_when(
duration >= lower_bound_duration & duration <= upper_bound_duration ~ 100,
duration >= (lower_bound_duration - 0.1 * (upper_bound_duration - lower_bound_duration)) &
duration <= (upper_bound_duration + 0.1 * (upper_bound_duration - lower_bound_duration)) ~ 50,
TRUE ~ 0
),
# Calificación para enfriador_total
score_enfriador_total = case_when(
enfriador_total >= lower_bound_enfriadores & enfriador_total <= upper_bound_enfriadores ~ 100,
enfriador_total >= (lower_bound_enfriadores - 0.1 * (upper_bound_enfriadores - lower_bound_enfriadores)) &
enfriador_total <= (upper_bound_enfriadores + 0.1 * (upper_bound_enfriadores - lower_bound_enfriadores)) ~ 50,
TRUE ~ 0
),
# Calificación para Num.Scenes
score_NumScenes = case_when(
Total_Scenes >= lower_bound_NumScenes & Total_Scenes <= upper_bound_NumScenes ~ 100,
Total_Scenes >= (lower_bound_NumScenes - 0.1 * (upper_bound_NumScenes - lower_bound_NumScenes)) &
Total_Scenes <= (upper_bound_NumScenes + 0.1 * (upper_bound_NumScenes - lower_bound_NumScenes)) ~ 50,
TRUE ~ 0
),
# Calificación para Scenes_Amb
score_ScenesAmb = case_when(
Ambiente_Scenes >= lower_bound_ScenesAmb & Ambiente_Scenes <= upper_bound_ScenesAmb ~ 100,
Ambiente_Scenes >= (lower_bound_ScenesAmb - 0.1 * (upper_bound_ScenesAmb - lower_bound_ScenesAmb)) &
Ambiente_Scenes <= (upper_bound_ScenesAmb + 0.1 * (upper_bound_ScenesAmb - lower_bound_ScenesAmb)) ~ 50,
TRUE ~ 0
),
# Calificación para Scenes_Frio
score_ScenesFrio = case_when(
Frio_Scenes >= lower_bound_ScenesFrio & Frio_Scenes <= upper_bound_ScenesFrio ~ 100,
Frio_Scenes >= (lower_bound_ScenesFrio - 0.1 * (upper_bound_ScenesFrio - lower_bound_ScenesFrio)) &
Frio_Scenes <= (upper_bound_ScenesFrio + 0.1 * (upper_bound_ScenesFrio - lower_bound_ScenesFrio)) ~ 50,
TRUE ~ 0
)
)
# Verificar el resultado
head(master_evaluado)
# Asegurándonos que SessionUID es del mismo tipo en ambos dataframes
df_session$SessionUID <- as.character(df_session$SessionUId)
master_evaluado$SessionUID <- as.character(master_evaluado$SessionUID)
# Uniendo las coordenadas de df_session a master_calidad
master_evaluado <- master_evaluado %>%
left_join(df_session %>% select(SessionUID, latitude, longitude),
by = "SessionUID")
# Obtener el mes y año actual automáticamente
mes_actual <- format(Sys.Date(), "%B_%Y")
# Leer o inicializar el archivo del mes
archivo_csv_mes <- paste0("data_procesada/", mes_actual, ".csv")
# Cargar datos del mes si el archivo existe, o crear un dataframe vacío si no existe
if (file.exists(archivo_csv_mes)) {
datos_mes <- read_csv(archivo_csv_mes)
} else {
datos_mes <- tibble() # Crear un tibble vacío
}
# Convertir todas las columnas comunes a character
columns_to_convert <- intersect(names(master_evaluado), names(datos_mes))
master_evaluado[columns_to_convert] <- lapply(master_evaluado[columns_to_convert], as.character)
datos_mes[columns_to_convert] <- lapply(datos_mes[columns_to_convert], as.character)
# Concatenar los datos nuevos con los antiguos
datos_combinados <- bind_rows(master_evaluado, datos_mes)
# Calcular la cantidad de NAs para cada fila antes de agrupar
datos_combinados <- datos_combinados %>%
mutate(cantidad_na = rowSums(is.na(.)))
# Seleccionar la entrada con menos NA para cada SessionUID
datos_actualizados <- datos_combinados %>%
group_by(SessionUID) %>%
arrange(cantidad_na) %>%
slice(1) %>%
ungroup() %>%
select(-cantidad_na)
# Guardar los datos actualizados en el archivo CSV del mes
write_csv(datos_actualizados, archivo_csv_mes)
# Mensaje de confirmación
cat("Los datos para", mes_actual, "han sido actualizados y guardados en", archivo_csv_mes, "\n")
library(tidyverse)
library(readr)
# Definir la carpeta donde se encuentran los datos
folder_path <- "data_procesada"
# Leer todos los archivos CSV en la carpeta
files <- list.files(path = folder_path, pattern = "*.csv", full.names = TRUE)
# Función para procesar cada archivo
process_file <- function(file_path) {
# Leer el archivo
data <- read_csv(file_path)
# Calcular la cantidad de NAs y 0s por fila
data <- data %>%
mutate(cantidad_na = rowSums(is.na(.)),
cantidad_ceros = rowSums(. == 0, na.rm = TRUE))
# Combinar las cantidades de NAs y 0s para tener un criterio de selección
data <- data %>%
mutate(cantidad_na_ceros = cantidad_na + cantidad_ceros)
# Seleccionar la entrada con menos NA y 0 para cada SessionUID y eliminar los contadores
data <- data %>%
group_by(SessionUID) %>%
arrange(cantidad_na_ceros) %>%
slice(1) %>%
ungroup() %>%
select(-c(cantidad_na, cantidad_ceros, cantidad_na_ceros))
# Guardar el archivo procesado
write_csv(data, file_path)
}
# Aplicar la función a cada archivo
walk(files, process_file)
# Mensaje de confirmación
cat("Todos los archivos en la carpeta", folder_path, "han sido procesados y limpiados considerando valores NA y 0.\n")
# Ruta a la carpeta con los archivos procesados
ruta_carpeta <- "data_procesada/"
# Obtener lista de todos los archivos CSV en la carpeta
archivos <- dir_ls(ruta_carpeta, regexp = "\\.csv$")
# Función para leer un archivo CSV y asegurarse de que todas las columnas sean del mismo tipo
leer_y_convertir <- function(archivo) {
df <- read_csv(archivo)
# Convertir todas las columnas a character para evitar conflictos
df[] <- lapply(df, as.character)
return(df)
}
# Leer cada archivo, convertir columnas y combinarlos en un solo dataframe
master_calidad <- map_dfr(archivos, leer_y_convertir)
# Asumiendo que master_calidad es tu dataframe
master_calidad <- master_calidad %>%
mutate(
duration = as.numeric(duration),
distance = as.numeric(distance),
frentes_total = as.numeric(frentes_total),
frentes_arca = as.numeric(frentes_arca),
sovi = as.numeric(sovi),
flag_trigger = as.numeric(flag_trigger),
enfriador_total = as.numeric(enfriador_total),
score_frentes_total = as.numeric(score_frentes_total),
score_frentes_arca = as.numeric(score_frentes_arca),
score_duration = as.numeric(score_duration),
score_enfriador_total = as.numeric(score_enfriador_total),
score_ScenesAmb = as.numeric(score_ScenesAmb),
score_ScenesFrio = as.numeric(score_ScenesFrio),
score_NumScenes = as.numeric(score_NumScenes),
latitude = as.numeric(latitude),
longitude = as.numeric(longitude),
estatus = as.numeric(estatus),
lower_bound_frentes = as.numeric(lower_bound_frentes),
upper_bound_frentes = as.numeric(upper_bound_frentes),
lower_bound_frentes_arca = as.numeric(lower_bound_frentes_arca),
upper_bound_frentes_arca = as.numeric(upper_bound_frentes_arca),
lower_bound_enfriadores = as.numeric(lower_bound_enfriadores),
upper_bound_enfriadores = as.numeric(upper_bound_enfriadores),
lower_bound_duration = as.numeric(lower_bound_duration),
upper_bound_duration = as.numeric(upper_bound_duration),
lower_bound_ScenesAmb = as.numeric(lower_bound_ScenesAmb),
upper_bound_ScenesAmb = as.numeric(upper_bound_ScenesAmb),
lower_bound_ScenesFrio = as.numeric(lower_bound_ScenesFrio),
upper_bound_ScenesFrio = as.numeric(upper_bound_ScenesFrio),
lower_bound_NumScenes = as.numeric(lower_bound_NumScenes),
upper_bound_NumScenes = as.numeric(upper_bound_NumScenes),
)
# Guardar el dataframe combinado como un archivo Excel
write.xlsx(master_calidad, "master_calidad.xlsx")
# Mensaje de confirmación
cat("El archivo 'master_calidad.xlsx' ha sido guardado con éxito.\n")
